{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3352f51",
   "metadata": {},
   "source": [
    "# ENCM 509 Lab Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60123201",
   "metadata": {},
   "source": [
    "Colton Osterlund - 30038785\n",
    "Boma Nkwonta - 30046333"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d7dce1",
   "metadata": {},
   "source": [
    "## Facial Detection Using OpenCV & DLib Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af1869f",
   "metadata": {},
   "source": [
    "Project Implementation Steps:\n",
    "\n",
    "• Choose 5-10 photos with one or two faces in it.\n",
    "\n",
    "• Convert to gray-scale.\n",
    "\n",
    "• Perform some pre-processing (such as histogram equalization, smoothing) if needed. This depends on the image\n",
    "quality.\n",
    "\n",
    "• Performs Face detection:\n",
    "\n",
    "– Investigate the original Haar cascades for the frontal face detection, by choosing 2-3 various values of the\n",
    "parameters of scalefactor, and minNeighbors. Compare the results, and draw conclusions.\n",
    "\n",
    "– Investigate the LBP-based Haar cascades for the frontal face detection, by choosing 2-3 various values of the\n",
    "parameters of scale ratio, step ratio, min size, max size. Compare the results, and draw conclusions.\n",
    "\n",
    "– Investigate the performance of the HOG+SVM face detection.\n",
    "\n",
    "• Evaluate the number of errors in face detection using the above approaches. Draw conclusions.\n",
    "\n",
    "• Creation of a Precision vs. Recall graph for each algorithm (with their best performing parameters). Which\n",
    "algorithm is superior in performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7efe10e",
   "metadata": {},
   "source": [
    "## Firstly - Import needed dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c222d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import dlib\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e1ecc0",
   "metadata": {},
   "source": [
    "## Set global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d9ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numImagesInSet = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c7d69b",
   "metadata": {},
   "source": [
    "## Choose 5-10 photos, each containing 1-2 faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ad4302",
   "metadata": {},
   "source": [
    "For this step, we will be using our own set of pictures - each of which contains 1-3 faces. The will be supplied along with the notebook in our submission of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e162a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseImagePath = \"./Images/FacialDetectionImage\"\n",
    "imageSet = []\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    #load image using the OpenCV imread call\n",
    "    img = cv.imread(baseImagePath + str(i) + \".PNG\")\n",
    "    if img is None:\n",
    "        sys.exit(\"Could not read the image.\")\n",
    "    imageSet.append(img)\n",
    "    cv.imshow('Raw Image ' + str(i), img)\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d0d59",
   "metadata": {},
   "source": [
    "## Convert all images to greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b904a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, numImagesInSet + 1):\n",
    "    #convert each image in our image set to a grey-scale image\n",
    "    imageSet[i - 1] = cv.cvtColor(imageSet[i - 1], cv.COLOR_BGR2GRAY)\n",
    "    cv.imshow('Grey-Scale Image ' + str(i), imageSet[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6608d012",
   "metadata": {},
   "source": [
    "## Perform image pre-processing to the images in the set\n",
    "For facial detection, it was found that the best pre-processing to do to the image includes:\n",
    " \n",
    " -histogram equalization\n",
    " \n",
    " -normalization\n",
    " \n",
    " -geometric correction\n",
    " \n",
    " -noise filtering / image sharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c27e31",
   "metadata": {},
   "source": [
    "### Histogram Equilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b16582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAM EQUILIZATION\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    imageSet[i - 1] = cv.equalizeHist(imageSet[i - 1])\n",
    "    cv.imshow('Histogram Equilized Image ' + str(i), imageSet[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da641a66",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "965ddc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZATION\n",
    "#set destination image and destination image set to export normalized images into\n",
    "imageDimensions = imageSet[0].shape\n",
    "normalizedImage = np.zeros(imageDimensions)\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    imageSet[i - 1] = cv.normalize(imageSet[i - 1], normalizedImage, 0, 255, cv.NORM_MINMAX)\n",
    "    cv.imshow('Normalized Image ' + str(i), imageSet[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf5f1f2",
   "metadata": {},
   "source": [
    "### Geometric Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7303cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GEOMETRIC CORRECTION\n",
    "# In our case, we chose images where our faces were looking directly at the camera,\n",
    "#therefore the geometric correction step is not required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838392f",
   "metadata": {},
   "source": [
    "### Noise Filtering / Image Sharpening\n",
    "\n",
    "To filter noise and sharpen an image, you can use the unsharp masking algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb1c9467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOISE FILTERING / IMAGE SHARPENING\n",
    "\n",
    "from scipy.ndimage.filters import median_filter\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    #Apply a Gausian Noise Filter\n",
    "    gaussianFilter = cv.GaussianBlur(imageSet[i - 1], (0, 0), 2.0)\n",
    "    \n",
    "    # Add weighted Gausian Filter to the original image\n",
    "    imageSet[i - 1] = cv.addWeighted(imageSet[i - 1], 2.0, gaussianFilter, -1.0, 0)\n",
    "    \n",
    "    cv.imshow('Sharpened Image ' + str(i), imageSet[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a5ac35",
   "metadata": {},
   "source": [
    "## Perform facial detection algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e2f4a4",
   "metadata": {},
   "source": [
    "### Original Haar Cascades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f859b209",
   "metadata": {},
   "source": [
    "#### Scale Factor = 1.0, minNeighbours = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d6f6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontFaceHaarCascade = cv.CascadeClassifier('./haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "mScaleFactor = 1.1\n",
    "mMinNeighbours = 5\n",
    "\n",
    "imageSetHaarCascade1 = imageSet\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detectMultiScale(imageSetHaarCascade1[i - 1], scaleFactor = mScaleFactor, minNeighbors = mMinNeighbours)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetHaarCascade1[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetHaarCascade1[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetHaarCascade1[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda4bfd",
   "metadata": {},
   "source": [
    "#### Scale Factor = 1.5, minNeighbours = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b10f043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mScaleFactor = 1.5\n",
    "mMinNeighbours = 5\n",
    "\n",
    "imageSetHaarCascade3 = imageSet\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detectMultiScale(imageSetHaarCascade3[i - 1], scaleFactor = mScaleFactor, minNeighbors = mMinNeighbours)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetHaarCascade3[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetHaarCascade3[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetHaarCascade3[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f3ffd1",
   "metadata": {},
   "source": [
    "#### Scale Factor = 1.9, minNeighbours = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ed2cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "mScaleFactor = 1.9\n",
    "mMinNeighbours = 5\n",
    "\n",
    "imageSetHaarCascade5 = imageSet\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detectMultiScale(imageSetHaarCascade5[i - 1], scaleFactor = mScaleFactor, minNeighbors = mMinNeighbours)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetHaarCascade5[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetHaarCascade5[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetHaarCascade5[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b6636",
   "metadata": {},
   "source": [
    "#### Scale Factor = 1.5, minNeighbours = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "724f58bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mScaleFactor = 1.5\n",
    "mMinNeighbours = 2\n",
    "\n",
    "imageSetHaarCascade6 = imageSet\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detectMultiScale(imageSetHaarCascade6[i - 1], scaleFactor = mScaleFactor, minNeighbors = mMinNeighbours)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetHaarCascade6[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetHaarCascade6[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetHaarCascade6[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ad8e4",
   "metadata": {},
   "source": [
    "#### Scale Factor = 1.5, minNeighbours = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66428abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mScaleFactor = 1.5\n",
    "mMinNeighbours = 7\n",
    "\n",
    "imageSetHaarCascade7 = imageSet\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detectMultiScale(imageSetHaarCascade7[i - 1], scaleFactor = mScaleFactor, minNeighbors = mMinNeighbours)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetHaarCascade7[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetHaarCascade7[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetHaarCascade7[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec003b",
   "metadata": {},
   "source": [
    "## LBP Cascades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d6c51",
   "metadata": {},
   "source": [
    "#### scale_ratio = , step_ratio = , min_size = , max_size = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fa1b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
