{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3352f51",
   "metadata": {},
   "source": [
    "# ENCM 509 Lab Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60123201",
   "metadata": {},
   "source": [
    "Colton Osterlund - 30038785\n",
    "Boma Nkwonta - 30046333"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d7dce1",
   "metadata": {},
   "source": [
    "## Facial Detection Using OpenCV & DLib Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af1869f",
   "metadata": {},
   "source": [
    "Project Implementation Steps:\n",
    "\n",
    "• Choose 5-10 photos with one or two faces in it.\n",
    "\n",
    "• Convert to gray-scale.\n",
    "\n",
    "• Perform some pre-processing (such as histogram equalization, smoothing) if needed. This depends on the image\n",
    "quality.\n",
    "\n",
    "• Performs Face detection:\n",
    "\n",
    "– Investigate the original Haar cascades for the frontal face detection, by choosing 2-3 various values of the\n",
    "parameters of scalefactor, and minNeighbors. Compare the results, and draw conclusions.\n",
    "\n",
    "– Investigate the LBP-based Haar cascades for the frontal face detection, by choosing 2-3 various values of the\n",
    "parameters of scale ratio, step ratio, min size, max size. Compare the results, and draw conclusions.\n",
    "\n",
    "– Investigate the performance of the HOG+SVM face detection.\n",
    "\n",
    "• Evaluate the number of errors in face detection using the above approaches. Draw conclusions.\n",
    "\n",
    "• Creation of a Precision vs. Recall graph for each algorithm (with their best performing parameters). Which\n",
    "algorithm is superior in performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7efe10e",
   "metadata": {},
   "source": [
    "## Firstly - Import needed dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4356f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import dlib\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "#creating deep copies of the imageSet\n",
    "import copy\n",
    "\n",
    "#noise filtering\n",
    "from scipy.ndimage.filters import median_filter\n",
    "\n",
    "#lbp cascades\n",
    "from skimage import data\n",
    "from skimage.feature import Cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e1ecc0",
   "metadata": {},
   "source": [
    "## Set global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "97d9ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numImagesInSet = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c7d69b",
   "metadata": {},
   "source": [
    "## Choose 5-10 photos, each containing 1-2 faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ad4302",
   "metadata": {},
   "source": [
    "For this step, we will be using our own set of pictures - each of which contains 1-3 faces. The will be supplied along with the notebook in our submission of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e162a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseImagePath = \"./Images/FacialDetectionImage\"\n",
    "imageSet = []\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    #load image using the OpenCV imread call\n",
    "    img = cv.imread(baseImagePath + str(i) + \".PNG\")\n",
    "    if img is None:\n",
    "        sys.exit(\"Could not read the image.\")\n",
    "    imageSet.append(img)\n",
    "    cv.imshow('Raw Image ' + str(i), img)\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d0d59",
   "metadata": {},
   "source": [
    "## Convert all images to greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0b904a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, numImagesInSet + 1):\n",
    "    #convert each image in our image set to a grey-scale image\n",
    "    imageSet[i - 1] = cv.cvtColor(imageSet[i - 1], cv.COLOR_BGR2GRAY)\n",
    "    cv.imshow('Grey-Scale Image ' + str(i), imageSet[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6608d012",
   "metadata": {},
   "source": [
    "## Perform image pre-processing to the images in the set\n",
    "For facial detection, it was found that the best pre-processing to do to the image includes:\n",
    " \n",
    " -histogram equalization\n",
    " \n",
    " -normalization\n",
    " \n",
    " -geometric correction\n",
    " \n",
    " -noise filtering / image sharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c27e31",
   "metadata": {},
   "source": [
    "### Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7b16582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAM EQUALIZATION\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    imageSet[i - 1] = cv.equalizeHist(imageSet[i - 1])\n",
    "    cv.imshow('Histogram Equalized Image ' + str(i), imageSet[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da641a66",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "965ddc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZATION\n",
    "#set destination image and destination image set to export normalized images into\n",
    "imageDimensions = imageSet[0].shape\n",
    "normalizedImage = np.zeros(imageDimensions)\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    imageSet[i - 1] = cv.normalize(imageSet[i - 1], normalizedImage, 0, 255, cv.NORM_MINMAX)\n",
    "    cv.imshow('Normalized Image ' + str(i), imageSet[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf5f1f2",
   "metadata": {},
   "source": [
    "### Geometric Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a7303cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GEOMETRIC CORRECTION\n",
    "# In our case, we chose images where our faces were looking directly at the camera,\n",
    "#therefore the geometric correction step is not required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838392f",
   "metadata": {},
   "source": [
    "### Noise Filtering / Image Sharpening\n",
    "\n",
    "To filter noise and sharpen an image, you can use the unsharp masking algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fb1c9467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOISE FILTERING / IMAGE SHARPENING\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    #Apply a Gausian Noise Filter\n",
    "    gaussianFilter = cv.GaussianBlur(imageSet[i - 1], (0, 0), 2.0)\n",
    "    \n",
    "    # Add weighted Gausian Filter to the original image\n",
    "    imageSet[i - 1] = cv.addWeighted(imageSet[i - 1], 2.0, gaussianFilter, -1.0, 0)\n",
    "    \n",
    "    cv.imshow('Sharpened Image ' + str(i), imageSet[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a5ac35",
   "metadata": {},
   "source": [
    "## Perform facial detection algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e2f4a4",
   "metadata": {},
   "source": [
    "### Original Haar Cascades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f859b209",
   "metadata": {},
   "source": [
    "#### Scale Factor = 1.0, minNeighbours = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3d6f6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontFaceHaarCascade = cv.CascadeClassifier('./haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "mScaleFactor = 1.1\n",
    "mMinNeighbours = 5\n",
    "\n",
    "imageSetHaarCascade1 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detectMultiScale(imageSetHaarCascade1[i - 1], scaleFactor = mScaleFactor, minNeighbors = mMinNeighbours)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetHaarCascade1[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetHaarCascade1[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetHaarCascade1[i - 1])\n",
    "    k = cv.waitKey(5000)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda4bfd",
   "metadata": {},
   "source": [
    "#### Scale Factor = 1.5, minNeighbours = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b10f043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mScaleFactor = 1.5\n",
    "mMinNeighbours = 5\n",
    "\n",
    "imageSetHaarCascade3 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detectMultiScale(imageSetHaarCascade3[i - 1], scaleFactor = mScaleFactor, minNeighbors = mMinNeighbours)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetHaarCascade3[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetHaarCascade3[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetHaarCascade3[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f3ffd1",
   "metadata": {},
   "source": [
    "#### Scale Factor = 1.9, minNeighbours = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2ed2cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "mScaleFactor = 1.9\n",
    "mMinNeighbours = 5\n",
    "\n",
    "imageSetHaarCascade5 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detectMultiScale(imageSetHaarCascade5[i - 1], scaleFactor = mScaleFactor, minNeighbors = mMinNeighbours)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetHaarCascade5[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetHaarCascade5[i - 1][y:y + h, x:x + w]\n",
    "\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetHaarCascade5[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b6636",
   "metadata": {},
   "source": [
    "#### Scale Factor = 1.5, minNeighbours = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "724f58bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mScaleFactor = 1.5\n",
    "mMinNeighbours = 2\n",
    "\n",
    "imageSetHaarCascade6 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detectMultiScale(imageSetHaarCascade6[i - 1], scaleFactor = mScaleFactor, minNeighbors = mMinNeighbours)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetHaarCascade6[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetHaarCascade6[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetHaarCascade6[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ad8e4",
   "metadata": {},
   "source": [
    "#### Scale Factor = 1.5, minNeighbours = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "66428abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mScaleFactor = 1.5\n",
    "mMinNeighbours = 7\n",
    "\n",
    "imageSetHaarCascade7 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detectMultiScale(imageSetHaarCascade7[i - 1], scaleFactor = mScaleFactor, minNeighbors = mMinNeighbours)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetHaarCascade7[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetHaarCascade7[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetHaarCascade7[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec003b",
   "metadata": {},
   "source": [
    "## LBP Cascades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d6c51",
   "metadata": {},
   "source": [
    "#### scale_ratio = 1.2, step_ratio = 1, min_size = (60, 60), max_size = (123, 123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "66fa1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontFaceHaarCascade = Cascade('./lbpcascades/lbpcascade_frontalcatface.xml')\n",
    "\n",
    "mscale_ratio = 1.2\n",
    "mstep_ratio = 1\n",
    "mmin_size = (60, 60)\n",
    "mmax_size = (123, 123)\n",
    "\n",
    "imageSetLBPCascade1 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detect_multi_scale(img = imageSetLBPCascade1[i - 1], \n",
    "                                                           scale_factor = mscale_ratio, \n",
    "                                                           step_ratio = mstep_ratio,\n",
    "                                                          min_size = mmin_size,\n",
    "                                                          max_size = mmax_size)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetLBPCascade1[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetLBPCascade1[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetLBPCascade1[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dea343f",
   "metadata": {},
   "source": [
    "#### scale_ratio = 1.5, step_ratio = 1, min_size = (60, 60), max_size = (123, 123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "169d2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscale_ratio = 1.5\n",
    "mstep_ratio = 1\n",
    "mmin_size = (60, 60)\n",
    "mmax_size = (123, 123)\n",
    "\n",
    "imageSetLBPCascade2 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detect_multi_scale(img = imageSetLBPCascade2[i - 1], \n",
    "                                                           scale_factor = mscale_ratio, \n",
    "                                                           step_ratio = mstep_ratio,\n",
    "                                                          min_size = mmin_size,\n",
    "                                                          max_size = mmax_size)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetLBPCascade2[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetLBPCascade2[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetLBPCascade2[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f2eb32",
   "metadata": {},
   "source": [
    "#### scale_ratio = 1.8, step_ratio = 1, min_size = (60, 60), max_size = (123, 123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c15f7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscale_ratio = 1.8\n",
    "mstep_ratio = 1\n",
    "mmin_size = (60, 60)\n",
    "mmax_size = (123, 123)\n",
    "\n",
    "imageSetLBPCascade3 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detect_multi_scale(img = imageSetLBPCascade3[i - 1], \n",
    "                                                           scale_factor = mscale_ratio, \n",
    "                                                           step_ratio = mstep_ratio,\n",
    "                                                          min_size = mmin_size,\n",
    "                                                          max_size = mmax_size)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetLBPCascade3[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetLBPCascade3[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetLBPCascade3[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd9646",
   "metadata": {},
   "source": [
    "#### scale_ratio = 1.2, step_ratio = 2, min_size = (60, 60), max_size = (123, 123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "95673e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscale_ratio = 1.2\n",
    "mstep_ratio = 2\n",
    "mmin_size = (60, 60)\n",
    "mmax_size = (123, 123)\n",
    "\n",
    "imageSetLBPCascade4 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detect_multi_scale(img = imageSetLBPCascade4[i - 1], \n",
    "                                                           scale_factor = mscale_ratio, \n",
    "                                                           step_ratio = mstep_ratio,\n",
    "                                                          min_size = mmin_size,\n",
    "                                                          max_size = mmax_size)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetLBPCascade4[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetLBPCascade4[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetLBPCascade4[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3624ebbc",
   "metadata": {},
   "source": [
    "#### scale_ratio = 1.2, step_ratio = 3, min_size = (60, 60), max_size = (123, 123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c7e88751",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscale_ratio = 1.2\n",
    "mstep_ratio = 3\n",
    "mmin_size = (60, 60)\n",
    "mmax_size = (123, 123)\n",
    "\n",
    "imageSetLBPCascade5 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detect_multi_scale(img = imageSetLBPCascade5[i - 1], \n",
    "                                                           scale_factor = mscale_ratio, \n",
    "                                                           step_ratio = mstep_ratio,\n",
    "                                                          min_size = mmin_size,\n",
    "                                                          max_size = mmax_size)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetLBPCascade5[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetLBPCascade5[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetLBPCascade5[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d5fdb3",
   "metadata": {},
   "source": [
    "#### scale_ratio = 1.2, step_ratio = 1, min_size = (20, 20), max_size = (123, 123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "51a2c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscale_ratio = 1.2\n",
    "mstep_ratio = 1\n",
    "mmin_size = (20, 20)\n",
    "mmax_size = (123, 123)\n",
    "\n",
    "imageSetLBPCascade6 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detect_multi_scale(img = imageSetLBPCascade6[i - 1], \n",
    "                                                           scale_factor = mscale_ratio, \n",
    "                                                           step_ratio = mstep_ratio,\n",
    "                                                          min_size = mmin_size,\n",
    "                                                          max_size = mmax_size)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetLBPCascade6[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetLBPCascade6[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetLBPCascade6[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e0119d",
   "metadata": {},
   "source": [
    "#### scale_ratio = 1.2, step_ratio = 1, min_size = (100, 100), max_size = (123, 123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "25ec07c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscale_ratio = 1.2\n",
    "mstep_ratio = 1\n",
    "mmin_size = (100, 100)\n",
    "mmax_size = (123, 123)\n",
    "\n",
    "imageSetLBPCascade7 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detect_multi_scale(img = imageSetLBPCascade7[i - 1], \n",
    "                                                           scale_factor = mscale_ratio, \n",
    "                                                           step_ratio = mstep_ratio,\n",
    "                                                          min_size = mmin_size,\n",
    "                                                          max_size = mmax_size)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetLBPCascade7[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetLBPCascade7[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetLBPCascade7[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0adeb74",
   "metadata": {},
   "source": [
    "#### scale_ratio = 1.2, step_ratio = 1, min_size = (60, 60), max_size = (80, 80) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2f9e3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscale_ratio = 1.2\n",
    "mstep_ratio = 1\n",
    "mmin_size = (60, 60)\n",
    "mmax_size = (80, 80)\n",
    "\n",
    "imageSetLBPCascade8 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detect_multi_scale(img = imageSetLBPCascade8[i - 1], \n",
    "                                                           scale_factor = mscale_ratio, \n",
    "                                                           step_ratio = mstep_ratio,\n",
    "                                                          min_size = mmin_size,\n",
    "                                                          max_size = mmax_size)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetLBPCascade8[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetLBPCascade8[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetLBPCascade8[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b8782a",
   "metadata": {},
   "source": [
    "#### scale_ratio = 1.2, step_ratio = 1, min_size = (60, 60), max_size = (190, 190) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "975598d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscale_ratio = 1.2\n",
    "mstep_ratio = 1\n",
    "mmin_size = (60, 60)\n",
    "mmax_size = (190, 190)\n",
    "\n",
    "imageSetLBPCascade9 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detect_multi_scale(img = imageSetLBPCascade9[i - 1], \n",
    "                                                           scale_factor = mscale_ratio, \n",
    "                                                           step_ratio = mstep_ratio,\n",
    "                                                          min_size = mmin_size,\n",
    "                                                          max_size = mmax_size)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetLBPCascade9[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetLBPCascade9[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetLBPCascade9[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c587fc",
   "metadata": {},
   "source": [
    "#### scale_ratio = 1.2, step_ratio = 1, min_size = (60, 60), max_size = (255, 255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "11433c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mscale_ratio = 1.2\n",
    "mstep_ratio = 1\n",
    "mmin_size = (60, 60)\n",
    "mmax_size = (255, 255)\n",
    "\n",
    "imageSetLBPCascade10 = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    faceDimensions = frontFaceHaarCascade.detect_multi_scale(img = imageSetLBPCascade10[i - 1], \n",
    "                                                           scale_factor = mscale_ratio, \n",
    "                                                           step_ratio = mstep_ratio,\n",
    "                                                          min_size = mmin_size,\n",
    "                                                          max_size = mmax_size)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(imageSetLBPCascade10[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = imageSetLBPCascade10[i - 1][y:y + h, x:x + w]\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), imageSetLBPCascade10[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b036923",
   "metadata": {},
   "source": [
    "## HOG + SVM Facial Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "30d54eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 1\n",
      "Score (0): 2.7183211483491774\n",
      "Score (1): 1.6374295391572828\n",
      "Score (2): 1.1902506985200758\n",
      "Score (3): -0.6584739531211432\n",
      "Score (4): -0.7155887446867113\n",
      "Score (5): -0.7919893870510615\n",
      "Score (6): -0.7970684469119118\n",
      "Score (7): -0.8774326742068337\n",
      "Score (8): -0.8864602888755377\n",
      "Score (9): -0.9575486788906611\n",
      "Score (10): -0.960348590724903\n",
      "Score (11): -0.96533697466718\n",
      "Score (12): -0.9748045410016153\n",
      "Score (13): -0.9818929992185716\n",
      "Score (14): -0.984748026261625\n",
      "\n",
      "Image 2\n",
      "Score (0): 1.0176323093904371\n",
      "Score (1): -0.7914614043699388\n",
      "Score (2): -0.9783531985746508\n",
      "\n",
      "Image 3\n",
      "Score (0): 1.3653128780855055\n",
      "Score (1): -0.683938916729558\n",
      "Score (2): -0.8947612251141641\n",
      "Score (3): -0.9386890540279902\n",
      "\n",
      "Image 4\n",
      "Score (0): 1.5485170521272535\n",
      "Score (1): 0.30700260777605726\n",
      "Score (2): -0.4298581088879678\n",
      "Score (3): -0.6540729365812425\n",
      "Score (4): -0.663623746441472\n",
      "Score (5): -0.8092364631162767\n",
      "Score (6): -0.8263030946627663\n",
      "Score (7): -0.8352182517208613\n",
      "Score (8): -0.856020625637639\n",
      "Score (9): -0.874207004421192\n",
      "Score (10): -0.8943581427268561\n",
      "Score (11): -0.9477130378583047\n",
      "\n",
      "Image 5\n",
      "Score (0): 2.096134964419734\n",
      "Score (1): 1.7311218418611403\n",
      "Score (2): 1.643758598758113\n",
      "Score (3): 0.8419950642122145\n",
      "Score (4): -0.6560555900433633\n",
      "Score (5): -0.6612568796053933\n",
      "Score (6): -0.8867703880169961\n",
      "Score (7): -0.9921492040530251\n",
      "\n",
      "Image 6\n",
      "Score (0): 0.9045727886690016\n",
      "Score (1): -0.6219982947043952\n",
      "Score (2): -0.741853853593168\n",
      "Score (3): -0.7418803534971361\n",
      "Score (4): -0.8976144636802252\n",
      "Score (5): -0.9534906707273607\n",
      "Score (6): -0.9605581606559332\n",
      "Score (7): -0.9840382541516397\n",
      "Score (8): -0.9955131853751715\n",
      "Score (9): -0.9988911757626093\n",
      "\n",
      "Image 7\n",
      "Score (0): 1.313469234897029\n",
      "Score (1): 0.953070942355525\n",
      "Score (2): 0.7681292091509726\n",
      "Score (3): -0.8278776611188028\n",
      "Score (4): -0.8793926844753779\n",
      "Score (5): -0.9988704622164772\n",
      "\n",
      "Image 8\n",
      "Score (0): 1.0896401559181634\n",
      "Score (1): 0.8503163494600172\n",
      "Score (2): 0.26922264691438214\n",
      "Score (3): -0.6290060840116625\n",
      "Score (4): -0.8141888583996866\n",
      "Score (5): -0.8816265426145677\n",
      "Score (6): -0.9702761019401129\n",
      "Score (7): -0.9971264804699991\n",
      "\n",
      "Image 9\n",
      "Score (0): 1.1473287140032675\n",
      "Score (1): -0.49371932398601137\n",
      "Score (2): -0.679056104229558\n",
      "Score (3): -0.8082230985537575\n",
      "Score (4): -0.8138048015104418\n",
      "Score (5): -0.8251070342527513\n",
      "Score (6): -0.84247907999907\n",
      "Score (7): -0.8770036063657884\n",
      "Score (8): -0.8792442287304971\n",
      "Score (9): -0.8953679502383278\n",
      "Score (10): -0.9102843413509882\n",
      "Score (11): -0.9875121722378291\n",
      "Score (12): -0.9884375537732217\n",
      "\n",
      "Image 10\n",
      "Score (0): 0.5926490463746901\n",
      "Score (1): -0.9834020743526972\n"
     ]
    }
   ],
   "source": [
    "HOGSVMDetector = dlib.get_frontal_face_detector()\n",
    "\n",
    "imageSetHOGSVC = copy.deepcopy(imageSet)\n",
    "\n",
    "for i in range(1, numImagesInSet + 1):\n",
    "    image = dlib.load_rgb_image(baseImagePath + str(i) + \".PNG\")\n",
    "    \n",
    "    faceDimensions, scores, idx = HOGSVMDetector.run(image, 1, -1)\n",
    "    \n",
    "    print(\"\\nImage {}\".format(i))\n",
    "    \n",
    "    for (j, d) in enumerate(faceDimensions):\n",
    "        print(\"Score ({}): {}\".format(j, scores[j]))\n",
    "        \n",
    "        cv.rectangle(imageSetHOGSVC[i - 1], (d.left(), d.top()), (d.right(), d.bottom()), (255, 0, 0), 2)\n",
    "        roi_gray = imageSetHOGSVC[i - 1][y:d.bottom(), x:d.right()]\n",
    "\n",
    "    cv.imshow('Face Detection ' + str(i), imageSetHOGSVC[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4f2d1b",
   "metadata": {},
   "source": [
    "### IoU Scores ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe479c",
   "metadata": {},
   "source": [
    "First, the coordinates of the ground-truth boxes are collected. Next, the coordinates of the facial recognition boxes from the Haar (Scale Factor = 1.1, minNeighbours = 5) and HOG+SVM algorithms are collected. These will be used to compute the IoU score (Intersection over Union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6093d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_event(event, x, y, flags, params):\n",
    " \n",
    "    # checking for left mouse clicks\n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    " \n",
    "        # displaying the coordinates\n",
    "        # on the Shell\n",
    "        print(x, ' ', y)\n",
    " \n",
    "        # displaying the coordinates\n",
    "        # on the image window\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        cv.putText(img, str(x) + ',' +\n",
    "                    str(y), (x,y), font,\n",
    "                    1, (255, 0, 0), 2)\n",
    "        cv.imshow('image', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d730e737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107   121\n",
      "108   259\n",
      "211   256\n",
      "211   123\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # reading the image\n",
    "    img = cv.imread('.\\Images\\MatLabGT1.png', 1)\n",
    "\n",
    "    cv.imshow('image', img)\n",
    "    cv.setMouseCallback('image', click_event)\n",
    "    cv.waitKey(0)\n",
    "    # close the window\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f8ec54c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261   178\n",
      "176   179\n",
      "260   68\n",
      "173   67\n"
     ]
    }
   ],
   "source": [
    "    img = cv.imread('.\\Images\\MatLabGT2.png', 1)\n",
    "\n",
    "    cv.imshow('image', img)\n",
    "    cv.setMouseCallback('image', click_event)\n",
    "    cv.waitKey(0)\n",
    "    # close the window\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b11f56c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205   205\n",
      "98   206\n",
      "204   71\n",
      "100   68\n"
     ]
    }
   ],
   "source": [
    "    img = cv.imread('.\\Images\\MatLabGT3.png', 1)\n",
    "\n",
    "    cv.imshow('image', img)\n",
    "    cv.setMouseCallback('image', click_event)\n",
    "    cv.waitKey(0)\n",
    "    # close the window\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cf6ac391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243   229\n",
      "162   230\n",
      "244   132\n",
      "159   131\n"
     ]
    }
   ],
   "source": [
    "    img = cv.imread('.\\Images\\MatLabGT4.png', 1)\n",
    "\n",
    "    cv.imshow('image', img)\n",
    "    cv.setMouseCallback('image', click_event)\n",
    "    cv.waitKey(0)\n",
    "    # close the window\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "284670a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dimensions = {}\n",
    "\n",
    "#Set for dimensions of ground truth boxes, format: x, y, x+w, y+h\n",
    "gt_dimensions[0] = [109, 124, 243, 227]\n",
    "gt_dimensions[1] = [174, 67, 260, 179]\n",
    "gt_dimensions[2] = [99, 69, 205, 206]\n",
    "gt_dimensions[3] = [163, 132, 243, 229]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8e6bf3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontFaceHaarCascade = cv.CascadeClassifier('./haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "iouImageSet = []\n",
    "iouImageSet.append(cv.imread('./Images/MatLabGT1.PNG'))\n",
    "iouImageSet.append(cv.imread('./Images/MatLabGT2.PNG'))\n",
    "iouImageSet.append(cv.imread('./Images/MatLabGT3.PNG'))\n",
    "iouImageSet.append(cv.imread('./Images/MatLabGT4.PNG'))\n",
    "\n",
    "iouImageDimensions = iouImageSet[0].shape\n",
    "normalizedIoUImage = np.zeros(imageDimensions)\n",
    "\n",
    "#Pre-processing\n",
    "for i in range(1, 5):\n",
    "    # Greyscale\n",
    "    iouImageSet[i - 1] = cv.cvtColor(iouImageSet[i - 1], cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Histogram Equalization\n",
    "    iouImageSet[i - 1] = cv.equalizeHist(iouImageSet[i - 1])\n",
    "\n",
    "    #Normalization\n",
    "    iouImageSet[i - 1] = cv.normalize(iouImageSet[i - 1], normalizedIoUImage, 0, 255, cv.NORM_MINMAX)\n",
    "\n",
    "    #Apply a Gausian Noise Filter\n",
    "    gaussianFilter = cv.GaussianBlur(iouImageSet[i - 1], (0, 0), 2.0)\n",
    "    \n",
    "    # Add weighted Gausian Filter to the original image\n",
    "    iouImageSet[i - 1] = cv.addWeighted(iouImageSet[i - 1], 2.0, gaussianFilter, -1.0, 0)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6442493d",
   "metadata": {},
   "source": [
    "Haar Cascade box dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f20f1f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 126, 229, 254]\n",
      "[168, 76, 269, 177]\n",
      "[87, 66, 221, 200]\n",
      "[163, 136, 241, 214]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "haarDimensions = []\n",
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    faceDimensions = frontFaceHaarCascade.detectMultiScale(iouImageSet[i - 1], scaleFactor = 1.1, minNeighbors = 5)\n",
    "\n",
    "    for (x, y, w, h) in faceDimensions:\n",
    "            cv.rectangle(iouImageSet[i - 1], (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            roi_gray = iouImageSet[i - 1][y:y + h, x:x + w]\n",
    "            haarDimensions.append([x, y, x+w, y+h])\n",
    "            print(haarDimensions[i-1])\n",
    "    \n",
    "    cv.imshow('Face Detection ' + str(i), iouImageSet[i - 1])\n",
    "    k = cv.waitKey(5000)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4928c931",
   "metadata": {},
   "source": [
    "HOG+SVM box dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5eebe641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 1\n",
      "96 139 225 268\n",
      "116 206 205 295\n",
      "\n",
      "Image 2\n",
      "175 86 265 176\n",
      "303 329 378 403\n",
      "\n",
      "Image 3\n",
      "103 92 211 199\n",
      "209 114 245 150\n",
      "279 343 331 395\n",
      "\n",
      "Image 4\n",
      "162 146 237 221\n"
     ]
    }
   ],
   "source": [
    "hogDimensions = []\n",
    "HOGSVMDetector = dlib.get_frontal_face_detector()\n",
    "\n",
    "for i in range(1,5):\n",
    "    image = dlib.load_rgb_image('./Images/MatLabGT' + str(i) + \".PNG\")\n",
    "    \n",
    "    faceDimensions, scores, idx = HOGSVMDetector.run(image, 1, -1)\n",
    "    \n",
    "    print(\"\\nImage {}\".format(i))\n",
    "    \n",
    "    for (j, d) in enumerate(faceDimensions):\n",
    "        #print(\"Score ({}): {}\".format(j, scores[j]))\n",
    "        \n",
    "        cv.rectangle(iouImageSet[i - 1], (d.left(), d.top()), (d.right(), d.bottom()), (255, 0, 0), 2)\n",
    "        roi_gray = iouImageSet[i - 1][y:d.bottom(), x:d.right()]\n",
    "        print(d.left(),  d.top(), d.right(), d.bottom())\n",
    "        hogDimensions.append([d.left(),  d.top(), d.right(), d.bottom()])\n",
    "\n",
    "    cv.imshow('Face Detection ' + str(i), iouImageSet[i - 1])\n",
    "    k = cv.waitKey(500)\n",
    "    cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12ab78b",
   "metadata": {},
   "source": [
    "Of these dimensions, we will drop the indexes that are too far from our ground-truth boxes (1, 3, 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "72cf81b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96, 139, 225, 268], [116, 206, 205, 295], [175, 86, 265, 176], [303, 329, 378, 403], [103, 92, 211, 199], [209, 114, 245, 150], [279, 343, 331, 395], [162, 146, 237, 221]]\n",
      "[[96, 139, 225, 268], [175, 86, 265, 176], [103, 92, 211, 199], [162, 146, 237, 221]]\n"
     ]
    }
   ],
   "source": [
    "# Dropping indexes that are out of range\n",
    "print(hogDimensions)\n",
    "del hogDimensions[1]\n",
    "del hogDimensions[2]\n",
    "del hogDimensions[3]\n",
    "del hogDimensions[3]\n",
    "\n",
    "print(hogDimensions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da19c03",
   "metadata": {},
   "source": [
    "## Area of Intersection / Area of Union ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7f81049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "\t# determine the (x, y)-coordinates of the intersection rectangle\n",
    "\txA = max(boxA[0], boxB[0])\n",
    "\tyA = max(boxA[1], boxB[1])\n",
    "\txB = min(boxA[2], boxB[2])\n",
    "\tyB = min(boxA[3], boxB[3])\n",
    "\n",
    "\t# compute the area of intersection rectangle\n",
    "\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "\t# compute the area of both the prediction and ground-truth\n",
    "\t# rectangles\n",
    "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "\t\n",
    "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\treturn iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "54c93f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 Haar Cascades IoU score 0.6729919842957631\n",
      "Image 2 Haar Cascades IoU score 0.7810932136255612\n",
      "Image 3 Haar Cascades IoU score 0.7486086818254094\n",
      "Image 4 Haar Cascades IoU score 0.7862181909800957\n"
     ]
    }
   ],
   "source": [
    "print(\"Image 1 Haar Cascades IoU score {}\".format(bb_intersection_over_union(gt_dimensions[0], haarDimensions[0])))\n",
    "print(\"Image 2 Haar Cascades IoU score {}\".format(bb_intersection_over_union(gt_dimensions[1], haarDimensions[1])))\n",
    "print(\"Image 3 Haar Cascades IoU score {}\".format(bb_intersection_over_union(gt_dimensions[2], haarDimensions[2])))\n",
    "print(\"Image 4 Haar Cascades IoU score {}\".format(bb_intersection_over_union(gt_dimensions[3], haarDimensions[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5af7c193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 HOG+SVM IoU score 0.5072830905636478\n",
      "Image 2 HOG+SVM IoU score 0.7608399766673148\n",
      "Image 3 HOG+SVM IoU score 0.7216815881666018\n",
      "Image 4 HOG+SVM IoU score 0.7112553032193661\n"
     ]
    }
   ],
   "source": [
    "print(\"Image 1 HOG+SVM IoU score {}\".format(bb_intersection_over_union(gt_dimensions[0], hogDimensions[0])))\n",
    "print(\"Image 2 HOG+SVM IoU score {}\".format(bb_intersection_over_union(gt_dimensions[1], hogDimensions[1])))\n",
    "print(\"Image 3 HOG+SVM IoU score {}\".format(bb_intersection_over_union(gt_dimensions[2], hogDimensions[2])))\n",
    "print(\"Image 4 HOG+SVM IoU score {}\".format(bb_intersection_over_union(gt_dimensions[3], hogDimensions[3])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
